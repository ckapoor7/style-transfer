{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image-style-transfer.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPas84QMdV6rSuvuXMDBcfI"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp9urvUDH14j"
      },
      "source": [
        "import time\n",
        "import os\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "from PIL import Image\n",
        "from collections import OrderedDict"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HP_bgjafJare"
      },
      "source": [
        "# VGG architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EDdROW1I4Z9"
      },
      "source": [
        "class VGG(nn.Module):\n",
        "\n",
        "  def __init__(self): \n",
        "    #construct VGG layers\n",
        "    #1st convolutional layer\n",
        "    self.conv1_1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)\n",
        "    self.conv1_2 = nn.Conv2d(64, 64, kernel_size=3, padding=1)\n",
        "\n",
        "    #2nd convolutional layer\n",
        "    self.conv2_1 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "    self.conv2_2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
        "\n",
        "    #3rd convolutional layer\n",
        "    self.conv3_1 = nn.Conv2d(128, 256, kernel_size=3, padding=1) \n",
        "    self.conv3_2 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "    self.conv3_3 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "    self.conv3_4 = nn.Conv2d(256, 256, kernel_size=3, padding=1)\n",
        "\n",
        "    #4th convolutional layer\n",
        "    self.conv4_1 = nn.Conv2d(256, 512, kernel_size=3, padding=1)\n",
        "    self.conv4_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.conv4_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.conv4_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    \n",
        "    #5th convolutional layer\n",
        "    self.conv5_1 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.conv5_2 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.conv5_3 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "    self.conv5_4 = nn.Conv2d(512, 512, kernel_size=3, padding=1)\n",
        "\n",
        "    #use average pooling (gives better results according to the paper)\n",
        "    self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.pool4 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "    self.pool5 = nn.AvgPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "    def forward(self, x, output_params):\n",
        "      #Forward propagation\n",
        "      #store weights in a ditcionary\n",
        "      ouput_weights = {}\n",
        "\n",
        "      #Block 1\n",
        "      output_weights['conv_layer1_1']  = F.relu(self.conv1_1(x))\n",
        "      output_weights['conv_layer1_2']  = F.relu(self.conv1_2(output_weights['conv_layer1_1']))\n",
        "      output_weights['pooling_layer1'] = self.pool1(output_weights['conv_layer1_2'])\n",
        "\n",
        "      #Block 2\n",
        "      output_weights['conv_layer2_1']  = F.relu(self.conv2_1(output_weights['pooling_layer1']))\n",
        "      output_weights['conv_layer2_2']  = F.relu(self.conv2_2(output_weights['conv_layer2_1']))\n",
        "      output_weights['pooling_layer2'] = self.pool2(output_weights['conv_layer2_2'])\n",
        "\n",
        "      #Block 3\n",
        "      output_weights['conv_layer3_1']  = F.relu(self.conv3_1(output_weights['pooling_layer2']))\n",
        "      output_weights['conv_layer3_2']  = F.relu(self.conv3_2(output_weights['conv_layer3_1']))\n",
        "      output_weights['conv_layer3_3']  = F.relu(self.conv3_3(output_weights['conv_layer3_2']))\n",
        "      output_weights['conv_layer3_4']  = F.relu(self.conv3_4(output_weights['conv_layer3_3']))\n",
        "      output_weights['pooling_layer3'] = self.pool3(output_weights['conv_layer3_4'])\n",
        "\n",
        "      #Block 4\n",
        "      output_weights['conv_layer4_1']  = F.relu(self.conv4_1(output_weights['pooling_layer3']))\n",
        "      output_weights['conv_layer4_2']  = F.relu(self.conv4_2(output_weights['conv_layer4_1']))\n",
        "      output_weights['conv_layer4_3']  = F.relu(self.conv4_3(output_weights['conv_layer4_2']))\n",
        "      output_weights['conv_layer4_4']  = F.relu(self.conv4_4(output_weights['conv_layer4_3']))\n",
        "      output_weights['pooling_layer4'] = self.pool4(output_weights['conv_layer4_4'])\n",
        "\n",
        "      #Block 5\n",
        "      output_weights['conv_layer5_1']  = F.relu(self.conv4_1(output_weights['pooling_layer4']))\n",
        "      output_weights['conv_layer5_2']  = F.relu(self.conv4_2(output_weights['conv_layer5_1']))\n",
        "      output_weights['conv_layer5_3']  = F.relu(self.conv4_3(output_weights['conv_layer5_2']))\n",
        "      output_weights['conv_layer5_4']  = F.relu(self.conv4_4(output_weights['conv_layer5_3']))\n",
        "      output_weights['pooling_layer5'] = self.pool5(output_weights['conv_layer5_4'])\n",
        "      \n",
        "      return [out[param] for param in output_params] #Return a list of the specified parameter weights"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8S4dYhTREpI"
      },
      "source": [
        "# Define Gram matrix and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A99OGdGSRD4-"
      },
      "source": [
        "class GramMatrix(nn.Module):\n",
        "  def forward(self, input):\n",
        "    batch, channel, height, width = input.size()\n",
        "    F = input.view(b, c, height*width) #flatten the matrix\n",
        "    '''\n",
        "    F: bxcx(h*w); F.transpose(1,2): bx(h*w)xc \n",
        "    Perform batch matrix multiplication using only the last 2\n",
        "    dimensions\n",
        "    '''\n",
        "    gram_matrix = torch.bmm(F, F.transpose(1,2))  \n",
        "    return gram_matrix.div_(h*w)\n",
        "\n",
        "\n",
        "#compute the style loss\n",
        "class GramMatrixStyleLoss(nn.Module):\n",
        "  def forward(self, input, target):\n",
        "    #I have used the MSE loss here (as detailed in the \n",
        "    #original paper)\n",
        "    return (nn.MSELoss()(GramMatrix()(input), target))"
      ],
      "execution_count": 4,
      "outputs": []
    }
  ]
}